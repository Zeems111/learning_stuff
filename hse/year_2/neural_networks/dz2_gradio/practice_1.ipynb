{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7AQMhMycA78"
      },
      "source": [
        "# Настраиваем окружение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dja8cY2TcA8A"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers datasets evaluate accelerate matplotlib torch torchvision scikit-learn pillow gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LH67NbifcA8C"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "# Helper function to set the seed in random, numpy, torch and/or tf (if installed).\n",
        "transformers.set_seed(42, deterministic=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esnUqGy-cA8D"
      },
      "source": [
        "# Готовим изображения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi4Gc-QNcA8D"
      },
      "source": [
        "https://huggingface.co/datasets/ethz/food101\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj9mruEJcA8D"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "dataset = datasets.load_dataset(\"food101\", split=\"train\")\n",
        "\n",
        "dataset = dataset.filter(lambda sample: sample[\"label\"] < 5)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ubzAY2ucA8E"
      },
      "outputs": [],
      "source": [
        "dataset[\"image\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVO_nBDAcA8E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "random_samples = np.random.randint(low=0, high=len(dataset), size=3)\n",
        "\n",
        "for index in random_samples:\n",
        "    display(dataset[\"image\"][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqg21Jl_cA8F"
      },
      "outputs": [],
      "source": [
        "dataset[\"label\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj_7A6sLcA8F"
      },
      "outputs": [],
      "source": [
        "labels = dataset.features[\"label\"].names[:5]\n",
        "\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q_sE0BgcA8F"
      },
      "outputs": [],
      "source": [
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl1htgkscA8F"
      },
      "outputs": [],
      "source": [
        "id2label[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG8OqXL8cA8G"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XEf1i-pcA8G"
      },
      "source": [
        "# Преобразуем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhb1koUcA8G"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "# checkpoint = \"microsoft/swin-tiny-patch4-window7-224\"\n",
        "# checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "checkpoint = \"microsoft/resnet-50\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlTZ-GAncA8G"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, Normalize, RandomResizedCrop, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqaXCVXDcA8H"
      },
      "outputs": [],
      "source": [
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DgJvfJ9cA8H"
      },
      "source": [
        "# Выбираем метрику для оценки качества"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anVL6VK5cA8H"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0ASAtEkcA8H"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_counts():\n",
        "    label_counts = Counter(dataset[\"train\"][\"label\"])\n",
        "\n",
        "    labels, counts = zip(*label_counts.items())\n",
        "    label_names = [id2label[label] for label in labels]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(label_names, counts, color=\"skyblue\")\n",
        "    plt.xlabel(\"Class Labels\")\n",
        "    plt.ylabel(\"Number of Samples\")\n",
        "    plt.title(\"Distribution of Samples per Class\")\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    for label, count in zip(label_names, counts):\n",
        "        print(f\"Class '{label}': {count} samples\")\n",
        "\n",
        "\n",
        "plot_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YwogpaRcA8H"
      },
      "source": [
        "# Грузим и обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd8Nk8_mcA8H"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aVvu_KvcA8H"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    report_to=\"none\",\n",
        "    output_dir=\"outputs\",\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=12,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_accuracy\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=DefaultDataCollator(),\n",
        "    train_dataset=dataset[\"train\"].with_transform(transforms),\n",
        "    eval_dataset=dataset[\"test\"].with_transform(transforms),\n",
        "    processing_class=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C2QIjoQcA8I"
      },
      "source": [
        "# Тестируем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIzHwQsncA8I"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"image-classification\", model=model, image_processor=image_processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fwkbgtcA8I"
      },
      "outputs": [],
      "source": [
        "index = 1\n",
        "\n",
        "display(dataset[\"test\"][\"image\"][index])\n",
        "print(f'True label: {id2label[dataset[\"test\"][\"label\"][index]]}\\n')\n",
        "print(\"Predictions:\")\n",
        "\n",
        "predictions = classifier(dataset[\"test\"][\"image\"][index])\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJydmu4ocA8I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "scores = torch.tensor([item[\"score\"] for item in predictions])\n",
        "probabilities = torch.nn.functional.softmax(scores, dim=0)\n",
        "probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t5R5tXecA8I"
      },
      "source": [
        "# Показываем результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-mz1MF3cA8I"
      },
      "outputs": [],
      "source": [
        "# import gradio as gr\n",
        "\n",
        "\n",
        "# def predict(image):\n",
        "#     predictions = classifier(image)\n",
        "#     scores = torch.tensor([item[\"score\"] for item in predictions])\n",
        "#     probabilities = torch.nn.functional.softmax(scores, dim=0)\n",
        "#     predicted_label = predictions[int(probabilities.argmax())][\"label\"]\n",
        "\n",
        "#     return predicted_label\n",
        "\n",
        "\n",
        "# interface = gr.Interface(\n",
        "#     fn=predict,\n",
        "#     inputs=gr.Image(type=\"pil\"),\n",
        "#     outputs=gr.Label(num_top_classes=6),\n",
        "# )\n",
        "\n",
        "# interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blec32XlcA8I"
      },
      "outputs": [],
      "source": [
        "# interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}