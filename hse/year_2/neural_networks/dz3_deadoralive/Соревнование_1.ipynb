{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMrwgsm17Ucs"
   },
   "source": [
    "# Подготовка окружения для соревнования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njty2vJ97Hy7",
    "outputId": "c13db1bd-2f1b-435b-bd8e-cf2d1469a66a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 0 ns (started: 2024-12-13 00:08:47 +03:00)\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipython-autotime kaggle --quiet\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZ8kfxLD70kk",
    "outputId": "2cb4d071-0075-442d-b811-041b08c4fa50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.3 s (started: 2024-12-12 23:02:13 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "9_lZU7PWixTV",
    "outputId": "b5ed68c9-6243-4ad3-9d74-21383bcd3fec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-697e13f2-e77f-4c21-907a-8b831eae82b4\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-697e13f2-e77f-4c21-907a-8b831eae82b4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "Downloading are-they-alive.zip to /content\n",
      " 82% 63.0M/77.1M [00:00<00:00, 219MB/s]\n",
      "100% 77.1M/77.1M [00:00<00:00, 132MB/s]\n",
      "time: 8.35 s (started: 2024-12-09 18:04:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# # Optionally, you can dowload the data right here, if you have Kaggle api token (kaggle.json)\n",
    "\n",
    "# # Upload your token\n",
    "# from google.colab import files\n",
    "# files.upload()\n",
    "\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# ! kaggle competitions download -c are-they-alive\n",
    "# ! unzip -q /content/are-they-alive.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4fHIZgLkNLu"
   },
   "source": [
    "# ВАШЕ РЕШЕНИЕ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-Nz8X2e64_b"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT35-2vdM3Nt",
    "outputId": "3942581b-81dc-47c5-f07b-4f993793e205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-13 00:08:52 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_dir = \"content/train_dataset\"\n",
    "test_dataset_dir = \"content/test_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNa9uHCb7cPN",
    "outputId": "8a878ae7-c601-4783-9f47-d83cae44c0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train dataset with 5000 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.4471, 0.3059],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6784, 0.5529, 0.4392],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6941, 0.5765, 0.4902],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.5098, 0.4118],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.5373, 0.4706],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5647, 0.5255]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.4471, 0.3059],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6863, 0.5608, 0.4431],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5843, 0.4941],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5216, 0.4235],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5529, 0.4824],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6157, 0.5804, 0.5373]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.4627, 0.3176],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.5686, 0.4549],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5882, 0.5059],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.5137, 0.4157],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5961, 0.5412, 0.4745],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5725, 0.5294]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.9 s (started: 2024-12-13 00:08:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the train dataset\n",
    "train_dataset = ImageFolder(root=train_dataset_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Loaded train dataset with {len(train_dataset)} samples\")\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.4471, 0.3059],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6784, 0.5529, 0.4392],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6941, 0.5765, 0.4902],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.5098, 0.4118],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.5373, 0.4706],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5647, 0.5255]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.4471, 0.3059],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6863, 0.5608, 0.4431],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5843, 0.4941],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5216, 0.4235],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5529, 0.4824],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6157, 0.5804, 0.5373]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.5922, 0.4627, 0.3176],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.5686, 0.4549],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7020, 0.5882, 0.5059],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5882, 0.5137, 0.4157],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.5961, 0.5412, 0.4745],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5725, 0.5294]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-13 00:09:27 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-11 20:42:38 +03:00)\n"
     ]
    }
   ],
   "source": [
    "#train_dataset[0][0]\n",
    "#b = torch.reshape(train_dataset[0][0], (3,4,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[211, 212],\n",
       "        [221, 222]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-13 00:07:32 +03:00)\n"
     ]
    }
   ],
   "source": [
    "tens = torch.tensor([\n",
    "                    [[111,112],\n",
    "                    [121,122]],\n",
    "                    [[211,212],\n",
    "                    [221,222]],\n",
    "                    [[311,312],\n",
    "                    [321,322]]\n",
    "               ])\n",
    "#t = torch.reshape(t, (3, 4,1))\n",
    "tens[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.2980, 0.1059, 0.0235],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.4471, 0.3059],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3490, 0.2196, 0.0784],\n",
      "         ...,\n",
      "         [0.8863, 0.8941, 0.8941,  ..., 0.7216, 0.5059, 0.2980],\n",
      "         [0.3294, 0.3255, 0.3255,  ..., 0.1059, 0.0941, 0.0863],\n",
      "         [0.9059, 0.9059, 0.8941,  ..., 0.7451, 0.5451, 0.3451]],\n",
      "\n",
      "        [[0.3137, 0.3059, 0.3020,  ..., 0.0902, 0.0824, 0.0784],\n",
      "         [0.9216, 0.9137, 0.8902,  ..., 0.8118, 0.6784, 0.4549],\n",
      "         [0.2941, 0.2863, 0.2784,  ..., 0.0824, 0.0706, 0.0706],\n",
      "         ...,\n",
      "         [0.5412, 0.5569, 0.6784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "         [0.0000, 0.0157, 0.0392,  ..., 0.0118, 0.0078, 0.0000],\n",
      "         [0.5961, 0.5569, 0.6000,  ..., 0.0706, 0.0627, 0.0549]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0039,  ..., 0.0627, 0.0000, 0.0000],\n",
      "         [0.3098, 0.3020, 0.2941,  ..., 0.2275, 0.2157, 0.2353],\n",
      "         [0.0000, 0.0157, 0.0706,  ..., 0.1804, 0.0471, 0.0000],\n",
      "         ...,\n",
      "         [0.4196, 0.4392, 0.4510,  ..., 0.5569, 0.4980, 0.4118],\n",
      "         [0.7451, 0.7451, 0.7529,  ..., 0.7569, 0.7569, 0.7647],\n",
      "         [0.4078, 0.4275, 0.4471,  ..., 0.5765, 0.5059, 0.4118]],\n",
      "\n",
      "        [[0.7333, 0.7294, 0.7294,  ..., 0.7686, 0.7686, 0.7725],\n",
      "         [0.3843, 0.4078, 0.4392,  ..., 0.5843, 0.4980, 0.4000],\n",
      "         [0.7529, 0.7451, 0.7412,  ..., 0.7922, 0.7843, 0.7843],\n",
      "         ...,\n",
      "         [0.4392, 0.4353, 0.4588,  ..., 0.5922, 0.5373, 0.4706],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4980, 0.4980, 0.5059,  ..., 0.6000, 0.5647, 0.5255]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_image)\n\u001b[0;32m     22\u001b[0m         new_images\u001b[38;5;241m.\u001b[39mappend((new_image, label))\n\u001b[1;32m---> 24\u001b[0m \u001b[43mcreate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[141], line 16\u001b[0m, in \u001b[0;36mcreate_images\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     14\u001b[0m     image_layer \u001b[38;5;241m=\u001b[39m t[layer]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image_layer)\n\u001b[1;32m---> 16\u001b[0m     new_image\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_layer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     18\u001b[0m new_image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(new_image, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m new_image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(new_image, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2024-12-13 00:31:16 +03:00)\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_images(x):\n",
    "    x, label = x[0], x[1]\n",
    "    permuts = list(permutations([0, 1, 2, 3], 4))\n",
    "    t = x.view((3, 4, 32, 32))\n",
    "    new_images = []\n",
    "\n",
    "    for order in tqdm(permuts):\n",
    "\n",
    "        new_image = []\n",
    "        for layer in range(3):\n",
    "            image_layer = t[layer]\n",
    "            print(image_layer)\n",
    "            new_image.append(torch.tensor([image_layer[i] for i in order]))\n",
    "        \n",
    "        new_image = torch.stack(new_image, dim=0)\n",
    "        new_image = torch.reshape(new_image, (3,64,64))\n",
    "        print(new_image)\n",
    "\n",
    "        new_images.append((new_image, label))\n",
    "\n",
    "create_images(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "        0.1412, 0.3137, 0.4510, 0.5020, 0.5020, 0.4941, 0.4863, 0.4745, 0.4706,\n",
       "        0.4667, 0.4706, 0.4706, 0.4627, 0.4588, 0.4549, 0.4588, 0.4627, 0.4431,\n",
       "        0.4196, 0.3961, 0.3490, 0.2196, 0.0784, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "        0.0353, 0.1176, 0.2863, 0.4706, 0.6392, 0.7765, 0.8588, 0.9059, 0.9255,\n",
       "        0.9333, 0.9333, 0.9294, 0.9176, 0.8431, 0.7569, 0.6510, 0.5333, 0.4275,\n",
       "        0.3412, 0.2824, 0.3765, 0.4980, 0.6118, 0.6980, 0.7294, 0.6784, 0.5529,\n",
       "        0.4392])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-13 00:18:55 +03:00)\n"
     ]
    }
   ],
   "source": [
    "t = train_dataset[0][0]\n",
    "t[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
       "        0.1412, 0.3137, 0.4510, 0.5020, 0.5020, 0.4941, 0.4863, 0.4745, 0.4706,\n",
       "        0.4667, 0.4706, 0.4706, 0.4627, 0.4588, 0.4549, 0.4588, 0.4627, 0.4431,\n",
       "        0.4196, 0.3961, 0.3490, 0.2196, 0.0784])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2024-12-13 00:18:56 +03:00)\n"
     ]
    }
   ],
   "source": [
    "t = torch.reshape(t,(3,4,32,32))\n",
    "t[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKliTQ42QlUJ",
    "outputId": "49fc0b2a-f3fb-412d-830c-28afeb7c44c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test dataset with 5000 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8745, 0.8824, 0.8863,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6275, 0.6706, 0.7059,  ..., 0.0157, 0.0078, 0.0039],\n",
       "          [0.5922, 0.5843, 0.5686,  ..., 0.0510, 0.0353, 0.0235],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.6941, 0.7255, 0.7373,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5176, 0.6039, 0.6627,  ..., 0.0157, 0.0078, 0.0039],\n",
       "          [0.6196, 0.6314, 0.6275,  ..., 0.0510, 0.0353, 0.0235],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.7255, 0.7569, 0.7569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6000, 0.6745, 0.7176,  ..., 0.0157, 0.0078, 0.0039],\n",
       "          [0.7216, 0.7255, 0.7176,  ..., 0.0510, 0.0353, 0.0235],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " 'test_image_0.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 344 ms (started: 2024-12-11 23:36:51 +03:00)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.root_dir.glob('*'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path.name\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create a custom dataset from the folder containing the images\n",
    "test_dataset = CustomImageDataset(root_dir=test_dataset_dir, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the images in batches\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Loaded test dataset with {len(test_dataset)} samples\")\n",
    "\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbSRIt4s8KbK"
   },
   "source": [
    "## Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldqxq7TR8Oz4",
    "outputId": "16e27e4b-4fc6-42a0-e4d1-41b90917386b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-12 01:01:57 +03:00)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.input_layer = nn.Conv2d(3, 8, kernel_size=3)\n",
    "      self.hidden1_layer = nn.Linear(8, 72)\n",
    "      self.hidden2_layer = nn.Linear(72, 64)\n",
    "      self.hidden3_layer = nn.Linear(64, 56)\n",
    "      self.hidden4_layer = nn.Linear(56, 32)\n",
    "      self.hidden5_layer = nn.Linear(32, 16)\n",
    "      self.output_layer = nn.Linear(16, 2)\n",
    "      # define your model here\n",
    "\n",
    "    def forward(self, x):\n",
    "       #x = x.view(-1, 3*64*64)\n",
    "       x = nn.ReLu(self.input_layer(x))\n",
    "       x = torch.sigmoid(self.hidden1_layer(x))\n",
    "       x = torch.sigmoid(self.hidden2_layer(x))\n",
    "       x = torch.sigmoid(self.hidden3_layer(x))\n",
    "       x = torch.sigmoid(self.hidden4_layer(x))\n",
    "       x = torch.sigmoid(self.hidden5_layer(x))\n",
    "       x = torch.sigmoid(self.output_layer(x))\n",
    "       return x\n",
    "    \n",
    "net = MyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (input_layer): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (hidden1_layer): Linear(in_features=8, out_features=72, bias=True)\n",
      "  (hidden2_layer): Linear(in_features=72, out_features=64, bias=True)\n",
      "  (hidden3_layer): Linear(in_features=64, out_features=56, bias=True)\n",
      "  (hidden4_layer): Linear(in_features=56, out_features=32, bias=True)\n",
      "  (hidden5_layer): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (output_layer): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "time: 0 ns (started: 2024-12-12 00:59:45 +03:00)\n"
     ]
    }
   ],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn--6chVRuoW",
    "outputId": "cdfb672b-5243-4bac-f8a5-439e08d6fdf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 11570\n",
      "False\n",
      "time: 0 ns (started: 2024-12-12 00:59:48 +03:00)\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Total number of parameters in the network: {total_params}\")\n",
    "print(f\"{total_params > 1_000_000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC7wRqptSJVZ"
   },
   "source": [
    "## Обучение модели и все остальное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-12 00:59:54 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "pr3Imvy2SU6R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-12 00:59:56 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# do everything you need to get the best result here\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.91 s (started: 2024-12-12 00:59:58 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_X = [image for image, _ in train_dataset]\n",
    "train_Y = train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 234 ms (started: 2024-12-12 01:00:14 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_X = torch.stack(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 3, 64, 64])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-12 00:37:28 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'ReLu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m image_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(torch\u001b[38;5;241m.\u001b[39mlog(output), torch\u001b[38;5;241m.\u001b[39mtensor(train_Y))\n\u001b[0;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[140], line 18\u001b[0m, in \u001b[0;36mMyNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     17\u001b[0m    \u001b[38;5;66;03m#x = x.view(-1, 3*64*64)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m    x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLu\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer(x))\n\u001b[0;32m     19\u001b[0m    x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden1_layer(x))\n\u001b[0;32m     20\u001b[0m    x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden2_layer(x))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'ReLu'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63 ms (started: 2024-12-12 01:02:08 +03:00)\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    image_k = 1\n",
    "    optimizer.zero_grad()\n",
    "    output = net(train_X)\n",
    "    loss = loss_function(torch.log(output), torch.tensor(train_Y))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 469 ms (started: 2024-12-12 00:39:17 +03:00)\n"
     ]
    }
   ],
   "source": [
    "images, _ = next(iter(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5206, 0.4825\n",
      "time: 0 ns (started: 2024-12-12 00:39:43 +03:00)\n"
     ]
    }
   ],
   "source": [
    "image = images[0]\n",
    "with torch.no_grad():\n",
    "    log_prob = net(image)\n",
    "\n",
    "prob = log_prob.tolist()\n",
    "prob = prob[0]\n",
    "print(f'{prob[0]:.4f}, {prob[1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.44 %\n",
      "time: 5.83 s (started: 2024-12-12 00:39:48 +03:00)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        output = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2528"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-12-12 00:40:41 +03:00)\n"
     ]
    }
   ],
   "source": [
    "train_Y.count(1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
