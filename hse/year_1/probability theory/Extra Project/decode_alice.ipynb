{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AZ914lSG-xyJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "from random import choices\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWSj-xmfGjPK"
      },
      "source": [
        "# Substitution Cipher\n",
        "\n",
        "In this task we will decrypt data that was scrambled using a Substitution Cipher. We assume that encryption key is unknown and we want to decrypt the data and read the code using recovered decryption key. [Introduction from here](http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf) gives reference to the original task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_QQHXU6-xyQ"
      },
      "source": [
        "As verification we will take a piece from \"Alice's adventures in Wonderland\". We scramble data with a random encryption key, which we forgot after encrypting, and we would like to decrypt this encrypted text using MCMC Chains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Ni5EZg6-xyR"
      },
      "outputs": [],
      "source": [
        "plain_text = \"\"\"\n",
        "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
        "So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
        "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, 'Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before see a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
        "In another moment down went Alice after it, never once considering how in the world she was to get out again.\n",
        "The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuZfYAGs-xyS"
      },
      "source": [
        "We will use 26 letters of English alphabet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D7LGgcd_-xyT"
      },
      "outputs": [],
      "source": [
        "characters = string.ascii_lowercase\n",
        "characters_dict = {char : c for c, char in enumerate(characters, start=1)}\n",
        "m = len(characters) + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y78vRGzN-xyU"
      },
      "source": [
        "## Generate random encryption key.\n",
        "\n",
        "Here are functions that will be used to encrypt/decrypt text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rG_G7itr-xyU"
      },
      "outputs": [],
      "source": [
        "def encode_text(text_to_encode, characters_dict):\n",
        "    \"\"\"This function turns a text string into an integer sequence using given dictionary.\"\"\"\n",
        "    characters_set = set(characters_dict.keys())\n",
        "    return np.r_[[characters_dict[char] if char in characters_set else 0 for char in text_to_encode.strip().lower()]]\n",
        "\n",
        "def decode_text(text_to_decode, characters):\n",
        "    \"\"\"This function turns an integer sequence into a text string using given list of characters.\"\"\"\n",
        "    characters_array = np.array([\" \"] + list(characters))\n",
        "    return \"\".join(characters_array[text_to_decode])\n",
        "\n",
        "def apply_cipher(text_as_int_array, cipher):\n",
        "    \"This function applies substitution cipher to an integer sequence.\"\n",
        "    return cipher[text_as_int_array]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd5EotfK-xyV"
      },
      "source": [
        "Generate encryption and decryption keys. They are just permutations of the alphabet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DlaPPUeL-xyW"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1234)\n",
        "encryption_indices = np.random.permutation(np.arange(m-1))\n",
        "decryption_indices = np.argsort(encryption_indices)\n",
        "characters_array = np.array(list(characters))\n",
        "encryption_key = \"\".join(characters_array[encryption_indices])\n",
        "decryption_key = \"\".join(characters_array[decryption_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbVIiWV6-xyW"
      },
      "source": [
        "Check encoding/decoding functions and encryption/decryption keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hCcbb4Sj-xyX"
      },
      "outputs": [],
      "source": [
        "encryption_key_encoded = np.r_[0, encode_text(encryption_key, characters_dict)]\n",
        "decryption_key_encoded = np.r_[0, encode_text(decryption_key, characters_dict)]\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "encoded_text = encode_text(text, characters_dict)\n",
        "cipher_text = apply_cipher(encoded_text, encryption_key_encoded)\n",
        "encoded_text = apply_cipher(cipher_text, decryption_key_encoded)\n",
        "decoded_text = decode_text(encoded_text, characters_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCVMBNlu-xyX"
      },
      "source": [
        "Encrypt cipher text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DnT3bAgB-xyX"
      },
      "outputs": [],
      "source": [
        "plain_text_encoded = encode_text(plain_text, characters_dict)\n",
        "cipher_text = apply_cipher(plain_text_encoded, encryption_key_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HmCvrVw-xyY"
      },
      "source": [
        "## Collect frequences\n",
        "\n",
        "Collect frequences of two character combinations (bigrams) over large text corpus and from encrypted text. We will store them in a matrix and interpret it as a transition matrix: from the first character to the second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a_RWjHE8-xyY"
      },
      "outputs": [],
      "source": [
        "def collect_transition_frequences(data, transition_matrix):\n",
        "    \"\"\"For a given integer sequence, which corresponds to some char sequence,\n",
        "       return transitions for adjacent values.\"\"\"\n",
        "    transitions = data.repeat(2)[1:-1].reshape(-1, 2)\n",
        "    for i, j in transitions:\n",
        "        transition_matrix[i, j] += 1\n",
        "\n",
        "    return transition_matrix\n",
        "\n",
        "def collect_empirical_frequences(filename, characters_dict, m):\n",
        "    \"\"\"Collect frequences over large text corpus, return transition matrix.\"\"\"\n",
        "    transition_matrix = np.zeros((m, m))\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            line_encoded = encode_text(line, characters_dict)\n",
        "            if line_encoded.size > 1:\n",
        "                transition_matrix = collect_transition_frequences(line_encoded, transition_matrix)\n",
        "\n",
        "    return transition_matrix\n",
        "\n",
        "def collect_observed_frequences(cipher_text, characters_dict, m):\n",
        "    \"\"\"Collect frequences over encrypted text, return nonzero indices of\n",
        "       transition matrix for both dimensions and values for those indices.\n",
        "       `values = transition_matrix[indices_1, indices_2]`\"\"\"\n",
        "    transition_matrix = np.zeros((m, m))\n",
        "    transition_matrix = collect_transition_frequences(cipher_text, transition_matrix)\n",
        "\n",
        "    return transition_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EcqRheW-xyZ"
      },
      "source": [
        "Collect frequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H6IUAya6-xyZ"
      },
      "outputs": [],
      "source": [
        "empirical_frequences = collect_empirical_frequences('war_and_peace.txt', characters_dict, m)\n",
        "observed_frequences = collect_observed_frequences(cipher_text, characters_dict, m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJP60qJa-xya"
      },
      "source": [
        "## General algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjedc-_xGjPO"
      },
      "source": [
        "Our Chain will include states that are permutations of the substitution cipher. Algorithm has following steps:\n",
        "\n",
        "1. Start by picking up a random current state.\n",
        "2. Create a proposal for a new state by swapping two or more random letters in the current state.\n",
        "3. Use a Scoring Function which calculates the score of the current state $Score_{old}$ and the proposed state $Score_{new}$.\n",
        "4. If the score of the proposed state is more than current state, Move to Proposed State.\n",
        "5. Else flip a coin which has a probability of Heads $\\frac{Score_{new}}{Score_{old}}$  . If it comes heads move to proposed State.\n",
        "6. Repeat from Step 2.\n",
        "\n",
        "We want to reach a steady state where the chain has the stationary distribution of the needed states. This state of chain could be used as a solution.\n",
        "\n",
        "Your goal is to implement steps 2 and 3 (see the templates below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UMIYsDf-xyb"
      },
      "source": [
        "## Step 2: Prepare sampling function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG0vNc4N-xyb"
      },
      "source": [
        "\n",
        "\n",
        "To generate a new proposed cipher we randomly select several positions and swap values at those positions. It corresponds to change in seveal mappings of encrypted characters in decrypted ones. Example with 2 swaps.\n",
        "\n",
        "was|now\n",
        "-|-\n",
        "A -> B | A -> B\n",
        "B -> C | B -> C\n",
        "C -> D | C -> A\n",
        "D -> A | D -> D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uzEd7nwd-xyb"
      },
      "outputs": [],
      "source": [
        "def generate_cipher(cipher, m, size=2):\n",
        "    \"\"\"Swap two or more random positions in cipher.\n",
        "\n",
        "        cipher, np.array - current mapping from value(int) in encrypted text (index of array cell) into value(int) in decrypted text(value of array cell).\n",
        "        m, int - capacity of used alphabet,\n",
        "        size, int - number of positions to change.\n",
        "    \"\"\"\n",
        "\n",
        "    # Your code here\n",
        "    new_cipher = np.array(cipher)\n",
        "    index = choices(range(m), k=size)\n",
        "    for i in range(size-1):\n",
        "        new_cipher[index[i]], new_cipher[index[i+1]] = new_cipher[index[i+1]], new_cipher[index[i]]\n",
        "    return new_cipher\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6is9fbf-xyc"
      },
      "source": [
        "## Step 3: Prepare scoring function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siBVVI9ZGjPP"
      },
      "source": [
        "We want to use a scoring function for each state(Decryption key) which assigns a positive score to each decryption key. This score intuitively should be larger if the encrypted text looks more like actual english, when decrypted using this decryption key. We will check a large text and calculate frequences: how many times one character comes after another in a large text like \"War and Peace\".\n",
        "\n",
        "For each pair of characters $\\beta_1$ and $\\beta_2$ (e.g. $\\beta_1$ = A and $\\beta_2$ = B), we let $R(\\beta_1,\\beta_2)$ record the number of times that specific pair(e.g. \"AB\") appears consecutively in the reference text.\n",
        "\n",
        "Similarly, for a considered decryption key $x$, we let $F_x(\\beta_1,\\beta_2)$ record the number of times that\n",
        "pair appears when the cipher text is decrypted using the decryption key $x$.\n",
        "\n",
        "We then Score a particular decryption key $x$ using:\n",
        "\n",
        "$$Score(x) = \\prod R(\\beta_1,\\beta_2)^{F_x(\\beta_1,\\beta_2)}$$\n",
        "    \n",
        "To make life easier with calculations we will calculate $log(Score(x))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB0ov7DB-xyd"
      },
      "source": [
        "Now, you need to implement scoring function. As input it takes\n",
        "- `cipher`: mapping between encrypted characters and decrypted characters,\n",
        "- `observed_frequences`: transition matrix for cipher text, matrix representation of $F_x(\\beta_1,\\beta_2)$,\n",
        "- `empirical_frequences`: transition matrix for large text, matrix representation of $R(\\beta_1,\\beta_2)$.\n",
        "\n",
        "Scoring function returns $log(Score(x))$. You need correctly process zero values in transition matrices while calculating the score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "L2TEC-jZ-xyd"
      },
      "outputs": [],
      "source": [
        "def score_cipher(cipher, observed_frequences, empirical_frequences):\n",
        "\n",
        "    # Your code here\n",
        "    F = observed_frequences\n",
        "    R = empirical_frequences\n",
        "    m = len(cipher)\n",
        "    score = 0\n",
        "    for i in range(m):\n",
        "        for j in range(m):\n",
        "            if R[cipher[i]][cipher[j]] > 0:\n",
        "                score += F[i][j]*np.log(R[cipher[i]][cipher[j]])\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEMcLFje-xyd"
      },
      "source": [
        "## Decryption\n",
        "\n",
        "Now we a ready to decrypt cipher text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jWwEgofR-xye"
      },
      "outputs": [],
      "source": [
        "def decrypting(observed_frequences, empirical_frequences, n_iters, m, step_size, seed, print_it=1000):\n",
        "    \"\"\"This function finds most suited decrypting cipher(1D np.array).\n",
        "        observed_frequences, 2D np.array - transition matrix with frequences for cipher text,\n",
        "        empirical_frequences, 2D np.array - transition matrix with frequences for large text,\n",
        "        n_iters, int - number of MCMC iterations,\n",
        "        step_size, int - number of changes in cipher per one iteration,\n",
        "        seed, int - seed for random generator,\n",
        "        print_it, int - print decrypted text every `print_it` iterations.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # 1. Start by picking up a random current state.\n",
        "    cipher_old = np.arange(m)\n",
        "    score_cipher_old = score_cipher(cipher_old, observed_frequences, empirical_frequences)\n",
        "    best_state, score = cipher_old, score_cipher_old\n",
        "\n",
        "    for i in tqdm(range(1, n_iters+1)):\n",
        "\n",
        "        # 2. Create a proposal for a new state by swapping two or more random letters in the current state.\n",
        "        cipher_new = generate_cipher(cipher_old, m, size=step_size)\n",
        "\n",
        "        # 3. Use a Scoring Function which calculates the score of the current state $Score_{old}$ and the proposed State $Score_{new}$.\n",
        "        score_cipher_new = score_cipher(cipher_new, observed_frequences, empirical_frequences)\n",
        "        acceptance_probability = np.min((1, np.exp(score_cipher_new - score_cipher_old)))\n",
        "\n",
        "        # 4. If the score of the proposed state is more than current state, Move to Proposed State.\n",
        "        # 5. Else flip a coin which has a probability of Heads $Score_{new}/Score_{old}$. If it comes heads move to proposed State.\n",
        "        if score_cipher_old > score:\n",
        "            best_state, score = cipher_old, score_cipher_old\n",
        "        if acceptance_probability > np.random.uniform(0,1):\n",
        "            cipher_old, score_cipher_old = cipher_new, score_cipher_new\n",
        "        if i % print_it == 0:\n",
        "            print(f\"iter {i}: {decode_text(apply_cipher(cipher_text[0:97], cipher_old), characters)}\")\n",
        "\n",
        "    return best_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "8651b25a70e44a55aecfbfda63914f23",
            "23ec45b35eb14a45ae39794220d8e6ad",
            "08636a89319d42e281dce97cd4a73f7b",
            "6c10fcc18475421fb403c32367f695ed",
            "fc0a31a18ec94640960c4c73e9e981a9",
            "702628e41a6a426a871990682c86e29a",
            "94d87c13858b47c69f4b8eeaf35354b3",
            "40d1b141ddf846f5aee69bbcb84d0365",
            "6dae8cb8b1724262a6a596ba42772646",
            "a6fc5714f6f24d18a3ff1558bfec136d",
            "ed2819985e74453ebfa87b80b5cce151"
          ]
        },
        "id": "Dvb_MS65L4rW",
        "outputId": "1e3f2b05-d60a-45b5-a79c-fac006140541"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/10000 [00:00<20:08,  8.27it/s]C:\\Temp\\ipykernel_11488\\586557026.py:25: RuntimeWarning: overflow encountered in exp\n",
            "  acceptance_probability = np.min((1, np.exp(score_cipher_new - score_cipher_old)))\n",
            " 11%|█         | 1067/10000 [00:02<00:16, 550.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 1000: ogise nor mewillilw ta wet vedy tidef ap rittilw my hed rirted al the molk  olf ap hovilw lathilw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 2098/10000 [00:04<00:15, 507.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 2000: odile won pecissisc ta cet very tirem af nittisc py her ninter as the posk  osm af hovisc sathisc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 3067/10000 [00:06<00:13, 525.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 3000: odile woc peginning ta get very tirem af citting py her cicter an the ponk  onm af hoving nathing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 4088/10000 [00:08<00:11, 526.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 4000: olice wos feginning ta get very tired ap sitting fy her sister an the fonk  ond ap hoving nathing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 5077/10000 [00:09<00:09, 542.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 5000: olice wos meginning ta get very tired af sitting my her sister an the monk  ond af hoving nathing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 6077/10000 [00:11<00:07, 538.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 6000: alice was meginning to get very tired of sitting my her sister on the mank  and of having nothing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 7080/10000 [00:13<00:05, 506.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 7000: alice was meginning to get very tired of sitting my her sister on the mank  and of having nothing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 8089/10000 [00:15<00:03, 512.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 8000: alice was meginning to get very tired of sitting my her sister on the mank  and of having nothing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 9089/10000 [00:17<00:01, 536.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 9000: alice was beginning to get very tired of sitting by her sister on the bank  and of having nothing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:19<00:00, 519.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 10000: alice was beginning to get very tired of sitting by her sister on the bank  and of having nothing\n",
            "\n",
            "Decoded Text: alice was beginning to get very tired of sitting by her sister on the bank  and of having nothing to do  once or twice she had peeped into the book her sister was reading  but it had no pictures or conversations in it   and what is the use of a book   thought alice  without pictures or conversation   so she was considering in her own mind  as well as she could  for the hot day made her feel very sleepy and stupid   whether the pleasure of making a daisy chain would be worth the trouble of getting up and picking the daisies  when suddenly a white rabbit with pink eyes ran close by her  there was nothing so very remarkable in that  nor did alice think it so very much out of the way to hear the rabbit say to itself   oh dear  oh dear  i shall be late    when she thought it over afterwards  it occurred to her that she ought to have wondered at this  but at the time it all seemed quite natural   but when the rabbit actually took a watch out of its waistcoat pocket  and looked at it  and then hurried on  alice started to her feet  for it flashed across her mind that she had never before see a rabbit with either a waistcoat pocket  or a watch to take out of it  and burning with curiosity  she ran across the field after it  and fortunately was just in time to see it pop down a large rabbit hole under the hedge  in another moment down went alice after it  never once considering how in the world she was to get out again  the rabbit hole went straight on like a tunnel for some way  and then dipped suddenly down  so suddenly that alice had not a moment to think about stopping herself before she found herself falling down a very deep well \n",
            "\n",
            "MCMC KEY  : iecdhgxajrmqvkpzbsfyuwolnt\n",
            "ACTual KEY: iecdhgxajrmqvkpzbsfyuwolnt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "decrypt_cipher = decrypting(observed_frequences, empirical_frequences, 10000, m, 4, 345, 1000)\n",
        "\n",
        "print(\n",
        "    f\"\\nDecoded Text: {decode_text(apply_cipher(cipher_text, decrypt_cipher), characters)}\\n\\n\"\n",
        "    f\"MCMC KEY  : {''.join(characters_array[decrypt_cipher[1:]-1])}\\n\"\n",
        "    f\"ACTual KEY: {decryption_key}\"\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foScyCjPPvKN"
      },
      "source": [
        "AFTER MANY ATTEMPTS I ACTUALLY GOT IT!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08636a89319d42e281dce97cd4a73f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d1b141ddf846f5aee69bbcb84d0365",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dae8cb8b1724262a6a596ba42772646",
            "value": 10000
          }
        },
        "23ec45b35eb14a45ae39794220d8e6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702628e41a6a426a871990682c86e29a",
            "placeholder": "​",
            "style": "IPY_MODEL_94d87c13858b47c69f4b8eeaf35354b3",
            "value": "100%"
          }
        },
        "40d1b141ddf846f5aee69bbcb84d0365": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c10fcc18475421fb403c32367f695ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fc5714f6f24d18a3ff1558bfec136d",
            "placeholder": "​",
            "style": "IPY_MODEL_ed2819985e74453ebfa87b80b5cce151",
            "value": " 10000/10000 [00:19&lt;00:00, 624.18it/s]"
          }
        },
        "6dae8cb8b1724262a6a596ba42772646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "702628e41a6a426a871990682c86e29a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8651b25a70e44a55aecfbfda63914f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ec45b35eb14a45ae39794220d8e6ad",
              "IPY_MODEL_08636a89319d42e281dce97cd4a73f7b",
              "IPY_MODEL_6c10fcc18475421fb403c32367f695ed"
            ],
            "layout": "IPY_MODEL_fc0a31a18ec94640960c4c73e9e981a9"
          }
        },
        "94d87c13858b47c69f4b8eeaf35354b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6fc5714f6f24d18a3ff1558bfec136d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed2819985e74453ebfa87b80b5cce151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc0a31a18ec94640960c4c73e9e981a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
